<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Home | Alexander Grindrod</title>
    <!-- Link to external CSS file -->
    <link rel="stylesheet" href="style.css">
</head>
<body>
    <header class = "header">
        <a href = "#" class="logo"></a>
        <nav class = "navbar">
            <a href = "index.html">Home</a>
            <a href = "experience.html" class="active">Experience/Research</a>
            <a href = "projects.html">Projects</a>
        </nav>
        <a href = "#" class="logo"></a>
    </header>

    <div class="timeline">
        <div class="container right-container">
            <img src="images/experience_page/UCIcircle.png" width=30%>
            <div class="text-box">
                    <h2>UCI Research - ML Acceleration</h2>
                    <h4>Undergraduate Research Assistant</h4>
                    <small>Sep. 2024 - Present</small>
                    <p>In my 4th year as an undergraduate at UCI, I joined Professor Thomas Yeh's research group - 
                        <a href="https://github.com/Arcala-Research-Lab" class="link">
                            ARCALA
                        </a>
                        <br><br>
                        My roles involved to leveraging UCI's HPC environment to run various experiments on the LLaMA 2 (7B) model with 
                        the mxfp and the Wanda repositories. I reported the perplexities generated by varying block size, weight/activation format types,
                        and pruning methods like magnitude, sparse-gpt, and Wanda. All of which were evaluated on the WikiText-2 benchmark.
                        I also curated these pruned models for future experimentation and conducted LoRA fine-tuning on such models to 
                        improve perplexity while maintaining sparsity. Overall, I have also analyzed and compared the algorithms of activation-aware
                        techniques like AWQ and Wanda to various other published works.
                    </p>
                    <span class="right-container-arrow"></span>
            </div>
        </div>
        <div class="container left-container">
            <img src="images/experience_page/trackonomycircle.png" width=30%>
            <div class="text-box">
                    <h2>Trackonomy Systems</h2>
                    <h4>Firmware Engineering Intern</h4>
                    <small>June 2024 - Sep. 2024</small>
                    <p>At Trackonomy, I served as an intern under the RFID firmware team. The duties of my role mainly involved
                        development of various Python and Bash scripts to expedite and automate various operations. My deliverables included: <br>
                        <br> • A framework to facilitate over the air updates to 600+ devices
                        <br> • Python test automation scripts to help with consistent reproduction of issues specifically for shutdown 
                        and information backup tests
                        <br> • Bash commands to view diagnostic information of hardware components and monitor logfile activity
                        <br>
                        <br>
                        Another core component of my internship involved performing white-box testing to analyze the interaction between the 
                        firmware and various hardware components - RFID Reader, PIR Sensor, OLED Display, and Embedded Modem. This required 
                        a thorough examination of the C++ code to understand its intended behavior and to identify potential bugs. 
                        
                    </p>
                    <span class="left-container-arrow"></span>
            </div>
        </div>
        <div class="container right-container">
            <img src="images/experience_page/UCIcircle.png" width=30%>
            <div class="text-box">
                    <h2>UCI Research - LLM Automation</h2>
                    <h4>Undergraduate Research Assistant</h4>
                    <small>Sep. 2023 - Mar. 2024</small>
                    <p>In my 3rd year as an undergraduate at UCI, I joined Professor Brian Demsky's research group. <br><br>
                        During the first quarter, we were tasked with exploring the capabilities of GPT-4 in helping
                        software engineers with various tasks such as debugging and end-to-end development. I was also
                        involved in stress testing a framework he developed, which created two separate GPT-4 sessions
                        to perform a software development task like developing a web application. One would act as a
                        teacher/senior developer to coach, and the other would be the student/junior developer to write
                        the code. <br><br> During my second quarter, I developed a script using this framework to allow the
                        lldb debugger to directly communicate with GPT-4 using the OpenAI python library and function call API. 
                        The advantage of this script being that a developer wouldn't need extensive knowledge of lldb to identify
                        bugs in an automated fashion. 
                    </p>
                    <span class="right-container-arrow"></span>
            </div>
        </div>
        <div class="container left-container">
            <img src="images/experience_page/fordcircle.png" width=30%>
            <div class="text-box">
                    <h2>Ford Motor Company</h2>
                    <h4>ADAS Software Engineering Intern</h4>
                    <small>June 2023 - Sep. 2023</small>
                    <p>During my summer at Ford I served as an undergraduate intern under the 
                        ADAS ML and MLOps teams.<br><br> My main responsiblities involved developing frameworks
                        to assist with the training and evaluation of PII-Masking Models. These models leveraged
                        computer vision to apply a blur to faces and license plates in videos. <br><br> My first deliverable, 
                        the evaluation framework, was required to help other engineers determine the quality of the PII-Masking model. 
                        The evaluation metrics included Precision, Recall, F2 Score, and Mean IOU. The program would also generate multiple comparison
                        graphs for PR Curves and F2 Score to help visualize a model's quality. <br><br> 
                        The training framework utilized TensorFlow's Object Detection API and the Faster R-CNN architecture for PII-Detection.
                        I also integrated a config for ease of changing various hyperparameters and added a system to enable transfer learning.
                        This way, the two frameworks could help with iterative improvement of the PII-Masking model's quality. <br><br>
                        I then prepared my frameworks for internal use on the HPC environment via Ray and Docker. The 
                        tools/libraries I used involved Python, OpenCV, FFMPEG and TensorFlow.</p>
                    <span class="left-container-arrow"></span>
            </div>
        </div>
       
    </div>
</body>


</html>
